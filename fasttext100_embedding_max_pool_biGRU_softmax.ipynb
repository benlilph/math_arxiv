{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 0.20.2\n",
      "keras version: 2.2.4\n",
      "tensorflow version: 2.0.0-dev20190314\n",
      "pandas version: 0.23.4\n",
      "numpy version: 1.15.1\n",
      "python version: 3.6.7 |Anaconda custom (64-bit)| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###now try to use keras to train the model\n",
    "###try deep learning \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import random\n",
    "import nltk.classify.util\n",
    "from gensim.models import FastText\n",
    "from gensim.models import FastText\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pickle\n",
    "import sklearn\n",
    "import sys\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import gensim \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import statistics\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "print(\"sklearn version:\",sklearn.__version__)\n",
    "print(\"keras version:\",keras.__version__)\n",
    "print(\"tensorflow version:\",tf.__version__)\n",
    "print(\"pandas version:\",pd.__version__)\n",
    "print(\"numpy version:\",np.__version__)\n",
    "print(\"python version:\",sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w{3,}')\n",
    "def simple_cleaning(test_str):\n",
    "    test_str = re.sub(r\"\\n\", \" \", test_str, 0, re.MULTILINE)\n",
    "    test_str = re.sub(r\"(\\$+)(?:(?!\\1)[\\s\\S])*\\1\", \"\", test_str, 0, re.MULTILINE)\n",
    "    test_str = re.sub(r\"-\", \" \", test_str, 0, re.MULTILINE)\n",
    "    test_str = re.sub(r\"[\\\\'/{}\\\":\\(\\).,]\", \"\", test_str, 0, re.MULTILINE)\n",
    "    test_str = test_str.lower()\n",
    "    return test_str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"complete_math_arxiv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>created</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>updated</th>\n",
       "      <th>clean_abstract</th>\n",
       "      <th>math.MP</th>\n",
       "      <th>...</th>\n",
       "      <th>math.SG</th>\n",
       "      <th>math.SP</th>\n",
       "      <th>math.CT</th>\n",
       "      <th>math.KT</th>\n",
       "      <th>math.GN</th>\n",
       "      <th>math.GM</th>\n",
       "      <th>math.HO</th>\n",
       "      <th>simple_abstract</th>\n",
       "      <th>list_simple_abstract</th>\n",
       "      <th>simple_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We construct a generic extension in which the ...</td>\n",
       "      <td>['Thomas Jech', 'Saharon Shelah']</td>\n",
       "      <td>['math.LO']</td>\n",
       "      <td>1989-04-14</td>\n",
       "      <td>math/9201239</td>\n",
       "      <td>A note on canonical functions</td>\n",
       "      <td>1989-04-14</td>\n",
       "      <td>construct gener extens aleph canon function al...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>construct generic exten canon function exist</td>\n",
       "      <td>['construct', 'generic', 'exten', 'canon', 'fu...</td>\n",
       "      <td>construct generic extens aleph_2 canon functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It is shown that if $C$ is an $n$-dimensional ...</td>\n",
       "      <td>['Keith Ball']</td>\n",
       "      <td>['math.MG', 'math.FA']</td>\n",
       "      <td>1989-10-26</td>\n",
       "      <td>math/9201205</td>\n",
       "      <td>Volume ratios and a reverse isoperimetric ineq...</td>\n",
       "      <td>1989-10-26</td>\n",
       "      <td>shown dimension convex bodi affin imag larger ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shown dimens convex bodi affin imag larger cor...</td>\n",
       "      <td>['shown', 'dimens', 'convex', 'bodi', 'affin',...</td>\n",
       "      <td>shown dimension convex bodi affin imag larger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It is proved that if $C$ is a convex body in $...</td>\n",
       "      <td>['Keith Ball']</td>\n",
       "      <td>['math.MG', 'math.FA']</td>\n",
       "      <td>1989-10-26</td>\n",
       "      <td>math/9201204</td>\n",
       "      <td>Shadows of convex bodies</td>\n",
       "      <td>1989-10-26</td>\n",
       "      <td>prove convex bodi affin imag zero volum codime...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>prove convex bodi affin imag non zero volum co...</td>\n",
       "      <td>['prove', 'convex', 'bodi', 'affin', 'imag', '...</td>\n",
       "      <td>prove convex bodi affin imag non zero volum co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>It is proved that if $u_1,\\ldots, u_n$ are vec...</td>\n",
       "      <td>['Keith Ball', 'Alain Pajor']</td>\n",
       "      <td>['math.MG', 'math.FA']</td>\n",
       "      <td>1989-10-26</td>\n",
       "      <td>math/9201203</td>\n",
       "      <td>Convex bodies with few faces</td>\n",
       "      <td>1989-10-26</td>\n",
       "      <td>prove vector volum symmetr convex bodi whose b...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>prove vector volum symmetr convex bodi whose b...</td>\n",
       "      <td>['prove', 'vector', 'volum', 'symmetr', 'conve...</td>\n",
       "      <td>prove vector volum symmetr convex bodi whose b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This note deals with the following problem, th...</td>\n",
       "      <td>['Gideon Schechtman', 'Joel Zinn']</td>\n",
       "      <td>['math.FA', 'math.MG']</td>\n",
       "      <td>1989-11-09</td>\n",
       "      <td>math/9201206</td>\n",
       "      <td>On the volume of the intersection of two $L_p^...</td>\n",
       "      <td>1989-11-09</td>\n",
       "      <td>note deal follow problem case introduc vitali ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>note deal follow problem case introduc vitali ...</td>\n",
       "      <td>['note', 'deal', 'follow', 'problem', 'case', ...</td>\n",
       "      <td>note deal follow problem case introduc vitali ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           abstract  \\\n",
       "0           0  We construct a generic extension in which the ...   \n",
       "1           1  It is shown that if $C$ is an $n$-dimensional ...   \n",
       "2           2  It is proved that if $C$ is a convex body in $...   \n",
       "3           3  It is proved that if $u_1,\\ldots, u_n$ are vec...   \n",
       "4           4  This note deals with the following problem, th...   \n",
       "\n",
       "                              authors              categories     created  \\\n",
       "0   ['Thomas Jech', 'Saharon Shelah']             ['math.LO']  1989-04-14   \n",
       "1                      ['Keith Ball']  ['math.MG', 'math.FA']  1989-10-26   \n",
       "2                      ['Keith Ball']  ['math.MG', 'math.FA']  1989-10-26   \n",
       "3       ['Keith Ball', 'Alain Pajor']  ['math.MG', 'math.FA']  1989-10-26   \n",
       "4  ['Gideon Schechtman', 'Joel Zinn']  ['math.FA', 'math.MG']  1989-11-09   \n",
       "\n",
       "             id                                              title  \\\n",
       "0  math/9201239                      A note on canonical functions   \n",
       "1  math/9201205  Volume ratios and a reverse isoperimetric ineq...   \n",
       "2  math/9201204                           Shadows of convex bodies   \n",
       "3  math/9201203                       Convex bodies with few faces   \n",
       "4  math/9201206  On the volume of the intersection of two $L_p^...   \n",
       "\n",
       "      updated                                     clean_abstract  math.MP  \\\n",
       "0  1989-04-14  construct gener extens aleph canon function al...        0   \n",
       "1  1989-10-26  shown dimension convex bodi affin imag larger ...        0   \n",
       "2  1989-10-26  prove convex bodi affin imag zero volum codime...        0   \n",
       "3  1989-10-26  prove vector volum symmetr convex bodi whose b...        0   \n",
       "4  1989-11-09  note deal follow problem case introduc vitali ...        0   \n",
       "\n",
       "                         ...                          math.SG  math.SP  \\\n",
       "0                        ...                                0        0   \n",
       "1                        ...                                0        0   \n",
       "2                        ...                                0        0   \n",
       "3                        ...                                0        0   \n",
       "4                        ...                                0        0   \n",
       "\n",
       "   math.CT  math.KT  math.GN  math.GM  math.HO  \\\n",
       "0        0        0        0        0        0   \n",
       "1        0        0        0        0        0   \n",
       "2        0        0        0        0        0   \n",
       "3        0        0        0        0        0   \n",
       "4        0        0        0        0        0   \n",
       "\n",
       "                                     simple_abstract  \\\n",
       "0       construct generic exten canon function exist   \n",
       "1  shown dimens convex bodi affin imag larger cor...   \n",
       "2  prove convex bodi affin imag non zero volum co...   \n",
       "3  prove vector volum symmetr convex bodi whose b...   \n",
       "4  note deal follow problem case introduc vitali ...   \n",
       "\n",
       "                                list_simple_abstract  \\\n",
       "0  ['construct', 'generic', 'exten', 'canon', 'fu...   \n",
       "1  ['shown', 'dimens', 'convex', 'bodi', 'affin',...   \n",
       "2  ['prove', 'convex', 'bodi', 'affin', 'imag', '...   \n",
       "3  ['prove', 'vector', 'volum', 'symmetr', 'conve...   \n",
       "4  ['note', 'deal', 'follow', 'problem', 'case', ...   \n",
       "\n",
       "                                         simple_text  \n",
       "0  construct generic extens aleph_2 canon functio...  \n",
       "1  shown dimension convex bodi affin imag larger ...  \n",
       "2  prove convex bodi affin imag non zero volum co...  \n",
       "3  prove vector volum symmetr convex bodi whose b...  \n",
       "4  note deal follow problem case introduc vitali ...  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['simple_abstract']=df['abstract'].apply(lambda x:simple_cleaning(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let we prepare the list of sent, each sent is a list of words\n",
    "## we will just skip stopwords and any words less than length 3\n",
    "###  use snowballstemmer to further clean the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "tokenizer_regex = RegexpTokenizer(r'\\w{3,}')\n",
    "df['list_simple_abstract']=df['simple_abstract'].apply(lambda x: tokenizer_regex.tokenize(x))\n",
    "from nltk.corpus import stopwords\n",
    "STOPS=set(stopwords.words('english'))\n",
    "df['list_simple_abstract'] = df['list_simple_abstract'].apply(lambda x : [stemmer.stem(y.strip()) for y in x if y not in STOPS])\n",
    "df['list_simple_abstract'] = df['list_simple_abstract'].apply(lambda x : [stemmer.stem(y.strip()) for y in x if (y not in STOPS) and (len(re.compile(r'\\d').findall(y))==0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['simple_abstract']=df['list_simple_abstract'].apply(lambda x :\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['simple_abstract'].apply(lambda x:type(x)==type(\"aaaa\"))]\n",
    "df['list_simple_abstract']=df['simple_abstract'].apply(lambda x: RegexpTokenizer(r'\\w{3,}').tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Preprocess\n",
    "def list_of_authors(text):\n",
    "    names=[]\n",
    "    name_list=text.split(',')\n",
    "    for name in name_list:\n",
    "        name=name.strip()\n",
    "        if name[0]=='[':\n",
    "            name=name[1:]\n",
    "        if name[-1]==']':\n",
    "            name=name[:-1]\n",
    "        name=name[1:-1]\n",
    "        names+=[name]\n",
    "    return names    \n",
    "\n",
    "\n",
    "def list_of_categories(text):\n",
    "    pat=re.compile(r'math.[A-Z][A-Z]')\n",
    "    return pat.findall(text)\n",
    "\n",
    "df['categories']=df['categories'].apply(lambda x: list_of_categories(x))\n",
    "df['authors']=df['authors'].apply(lambda x: list_of_authors(x))\n",
    "df['created']=df['created'].apply(lambda x:datetime.datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "if \"clean_abstract\" not in df.columns:\n",
    "    df['clean_abstract']=df['abstract'].apply(lambda x: clean.transform(x))\n",
    "      \n",
    "all_cat={}\n",
    "for i in df.index:\n",
    "    paper_cats=df.loc[i,\"categories\"]\n",
    "    for cat in paper_cats:\n",
    "        if cat in all_cat:\n",
    "            all_cat[cat]+=1\n",
    "        else:\n",
    "            all_cat[cat]=1\n",
    "\n",
    "list_of_all_cat=sorted(list(all_cat.items()),key=lambda x: x[1], reverse=True)            \n",
    "all_cats=list(zip(*list_of_all_cat))[0]\n",
    "index_to_cat={}\n",
    "for i in range(len(all_cats)):\n",
    "    index_to_cat[i]=all_cats[i]    \n",
    "\n",
    "for i in range(len(index_to_cat)):\n",
    "    df[index_to_cat[i]]=df[\"categories\"].apply(lambda x: 1 if index_to_cat[i] in x else 0)\n",
    "\n",
    "      \n",
    "###make \n",
    "\n",
    "df=df[df['clean_abstract'].apply(lambda x : type(x)!=type(3.0))]\n",
    "df=df[df['categories'].apply(lambda x : len(x)>0)]    \n",
    "df=df.reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pat=re.compile(r'\\'(\\w+)\\'')\n",
    "#df['list_simple_abstract']=df['list_simple_abstract'].apply(lambda x: pat.findall(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df[df['created']<=datetime.datetime(year=2017,month=1,day=1)]\n",
    "valid=df[(df['created']<datetime.datetime(year=2018,month=1,day=1))&(df['created']>datetime.datetime(year=2017,month=1,day=1))]\n",
    "test=df[df['created']>=datetime.datetime(year=2018,month=1,day=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText\n",
    "### Now we can try FastText\n",
    "### One cool thing about FastText is that it doesn't require us to see the wrod before.\n",
    "### Now we can directly process each input text as a matrix of the form (max_len,max_features), where max_len is the padded sequence length and max_features is the dim of embedding matrix of fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "max_feature= 100\n",
    "model_ted = FastText(list(df['list_simple_abstract']), size=max_feature, window=5, min_count=3, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ted.save(\"FastText100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ted = FastText.load(\"FastText100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = list(model_ted.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words=[]\n",
    "for i in df.index:\n",
    "    all_words+=df.loc[i,'list_simple_abstract']\n",
    "all_words=set(all_words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_feature= 100\n",
    "\n",
    "big_embedding=np.zeros(shape=(len(all_words),max_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "def embedding_fasttext(list_words,max_len,max_features):\n",
    "    mat=np.zeros(shape=(max_len,max_features))\n",
    "    temp_list_words=[]\n",
    "    for x in list_words:\n",
    "        if x.strip() in model_ted.wv:\n",
    "            temp_list_words+=[x.strip()]\n",
    "    list_words=temp_list_words\n",
    "    \n",
    "    if len(list_words)>=200:\n",
    "        for i in range(200):\n",
    "            mat[i,:]=model_ted.wv[list_words[i]]\n",
    "    else:\n",
    "        length=len(list_words)\n",
    "        for i in range(200-length,200):\n",
    "            mat[i,:]=model_ted.wv[list_words[i-(200-length)]]\n",
    "    return mat        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(list(df['simple_abstract']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding():\n",
    "    embedding=np.zeros(shape=(len(tokenizer.word_index)+1,100))\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if word in model_ted.wv:\n",
    "            embedding[index,]=model_ted.wv[word]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = build_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now we can train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314423\n",
      "37049\n",
      "36338\n"
     ]
    }
   ],
   "source": [
    "train=df[df['created']<=datetime.datetime(year=2017,month=1,day=1)]\n",
    "valid=df[(df['created']<datetime.datetime(year=2018,month=1,day=1))&(df['created']>datetime.datetime(year=2017,month=1,day=1))]\n",
    "test=df[df['created']>=datetime.datetime(year=2018,month=1,day=1)]\n",
    "print(len(train))\n",
    "print(len(valid))\n",
    "print(len(test))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(train['simple_abstract'])\n",
    "list_tokenized_valid = tokenizer.texts_to_sequences(valid['simple_abstract'])\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(test['simple_abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134544, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.11450e+04, 1.57326e+05, 8.42340e+04, 3.67780e+04, 1.41540e+04,\n",
       "        4.05600e+03, 9.50000e+01, 1.30000e+01, 5.00000e+00, 4.00000e+00]),\n",
       " array([  1. ,  31.8,  62.6,  93.4, 124.2, 155. , 185.8, 216.6, 247.4,\n",
       "        278.2, 309. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGpKkzgwNSVJnhoYkqTNDQ5LU2f8HX+JJQQjpAOYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_lengths=list(df['list_simple_abstract'].apply(lambda x:len(x)))\n",
    "plt.hist(all_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choose the padding length to be 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "X_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_valid = pad_sequences(list_tokenized_valid, maxlen=maxlen)\n",
    "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout1D,Input\n",
    "from keras.layers import GRU,GlobalAveragePooling1D,GlobalMaxPooling1D,Conv1D,concatenate\n",
    "num_class=len(index_to_cat)\n",
    "inp = tf.keras.layers.Input(shape=(200, ))\n",
    "###then do embedding\n",
    "embed_size = 100\n",
    "max_features = embedding_matrix.shape[0]\n",
    "x = tf.keras.layers.Embedding(max_features, embed_size,weights=[embedding_matrix],trainable=True)(inp)\n",
    "\n",
    "\n",
    "### then do LSTM\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(50,name='LSTM_layer',return_sequences=True))(x)\n",
    "### 1D conv\n",
    "#x = Conv1D(256, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "\n",
    "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "### maxpool\n",
    "#x = GlobalMaxPool1D()(x)\n",
    "### batchnor\n",
    "#x = BatchNormalization()(x)\n",
    "#x = Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "### dropout\n",
    "#x = Dropout(0.1)(x)\n",
    "### relu\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "### dropout\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "###\n",
    "#x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(num_class , activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 200, 100)          13454400  \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 200, 100)          45600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 13,508,544\n",
      "Trainable params: 13,508,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_index={}\n",
    "for i in range(len(index_to_cat)):\n",
    "    cat_to_index[index_to_cat[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(row):\n",
    "    temp=[0]*len(index_to_cat)\n",
    "    ind=cat_to_index[row['categories'][0]]\n",
    "    temp[ind]=1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.apply(lambda row:make_one_hot(row),axis=1)\n",
    "y_train = np.array(list(y_train))\n",
    "y_valid = valid.apply(lambda row:make_one_hot(row),axis=1)\n",
    "y_valid = np.array(list(y_valid))\n",
    "y_test = test.apply(lambda row:make_one_hot(row),axis=1)\n",
    "y_test = np.array(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 314423 samples, validate on 37049 samples\n",
      "Epoch 1/6\n",
      "314368/314423 [============================>.] - ETA: 0s - loss: 1.3068 - categorical_accuracy: 0.6211\n",
      "Epoch 00001: val_loss improved from inf to 0.96899, saving model to /Users/ben/Documents/NLP project/weaken_fasttext200_embedding_max_pool_biGRU.h5\n",
      "314423/314423 [==============================] - 2126s 7ms/sample - loss: 1.3068 - categorical_accuracy: 0.6211 - val_loss: 0.9690 - val_categorical_accuracy: 0.7097\n",
      "Epoch 2/6\n",
      "314368/314423 [============================>.] - ETA: 0s - loss: 0.9300 - categorical_accuracy: 0.7205\n",
      "Epoch 00002: val_loss improved from 0.96899 to 0.93017, saving model to /Users/ben/Documents/NLP project/weaken_fasttext200_embedding_max_pool_biGRU.h5\n",
      "314423/314423 [==============================] - 2119s 7ms/sample - loss: 0.9300 - categorical_accuracy: 0.7206 - val_loss: 0.9302 - val_categorical_accuracy: 0.7203\n",
      "Epoch 3/6\n",
      "314368/314423 [============================>.] - ETA: 0s - loss: 0.7846 - categorical_accuracy: 0.7615\n",
      "Epoch 00003: val_loss did not improve from 0.93017\n",
      "314423/314423 [==============================] - 4827s 15ms/sample - loss: 0.7846 - categorical_accuracy: 0.7615 - val_loss: 0.9515 - val_categorical_accuracy: 0.7152\n",
      "Epoch 4/6\n",
      "314368/314423 [============================>.] - ETA: 0s - loss: 0.6672 - categorical_accuracy: 0.7952\n",
      "Epoch 00004: val_loss did not improve from 0.93017\n",
      "314423/314423 [==============================] - 2078s 7ms/sample - loss: 0.6672 - categorical_accuracy: 0.7952 - val_loss: 1.0113 - val_categorical_accuracy: 0.7119\n",
      "Epoch 5/6\n",
      "314368/314423 [============================>.] - ETA: 0s - loss: 0.5717 - categorical_accuracy: 0.8235\n",
      "Epoch 00005: val_loss did not improve from 0.93017\n",
      "314423/314423 [==============================] - 4121s 13ms/sample - loss: 0.5717 - categorical_accuracy: 0.8235 - val_loss: 1.0615 - val_categorical_accuracy: 0.7079\n",
      "Epoch 6/6\n",
      "314368/314423 [============================>.] - ETA: 0s - loss: 0.4936 - categorical_accuracy: 0.8457\n",
      "Epoch 00006: val_loss did not improve from 0.93017\n",
      "314423/314423 [==============================] - 2818s 9ms/sample - loss: 0.4936 - categorical_accuracy: 0.8457 - val_loss: 1.1657 - val_categorical_accuracy: 0.7040\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "batch_size = 64\n",
    "epochs = 6\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=cwd+\"/weaken_fasttext100_embedding_max_pool_biGRU.h5\", verbose=1, save_best_only=True)\n",
    "history = model.fit(X_train,y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid),callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314423/314423 [==============================] - 985s 3ms/sample - loss: 0.3542 - categorical_accuracy: 0.8905\n",
      "37049/37049 [==============================] - 117s 3ms/sample - loss: 1.1657 - categorical_accuracy: 0.7040\n",
      "Train: 0.891, Test: 0.704\n"
     ]
    }
   ],
   "source": [
    "_, train_acc = model.evaluate(X_train, y_train, verbose=1)\n",
    "_, test_acc = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot training history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDWm4K6WUG9JwV0opN6ThrpRSbuj/Ab9B6WLlCFM0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=tf.keras.models.load_model('weaken_fasttext100_embedding_max_pool_biGRU.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36338/36338 [==============================] - 91s 2ms/sample - loss: 0.9274 - categorical_accuracy: 0.7181\n",
      "0.71814626\n"
     ]
    }
   ],
   "source": [
    "_, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true2=y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269910358905622"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true2, y_pred2, average='macro')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('math.MP', 0.6206398845321145),\n",
       " ('math.CO', 0.7962264150943397),\n",
       " ('math.AG', 0.7506603275224512),\n",
       " ('math.PR', 0.7414500683994528),\n",
       " ('math.AP', 0.7871287128712872),\n",
       " ('math.DG', 0.7248110831234256),\n",
       " ('math.IT', 0.8652959943282524),\n",
       " ('math.NT', 0.7637603507062835),\n",
       " ('math.DS', 0.6398820493918171),\n",
       " ('math.OC', 0.7787934186471663),\n",
       " ('math.FA', 0.6100449162923642),\n",
       " ('math.RT', 0.6347452424800492),\n",
       " ('math.NA', 0.7937655297040885),\n",
       " ('math.GT', 0.7062841530054644),\n",
       " ('math.QA', 0.49629629629629635),\n",
       " ('math.CA', 0.47926763597199784),\n",
       " ('math.GR', 0.6877828054298643),\n",
       " ('math.ST', 0.730072463768116),\n",
       " ('math.RA', 0.5474254742547425),\n",
       " ('math.CV', 0.5925215723873442),\n",
       " ('math.AT', 0.6077457795431976),\n",
       " ('math.OA', 0.6379542395693135),\n",
       " ('math.AC', 0.6836616454229432),\n",
       " ('math.LO', 0.749611197511664),\n",
       " ('math.MG', 0.4801223241590214),\n",
       " ('math.SG', 0.6590909090909091),\n",
       " ('math.SP', 0.4155339805825243),\n",
       " ('math.CT', 0.6421663442940039),\n",
       " ('math.KT', 0.3303571428571429),\n",
       " ('math.GN', 0.532258064516129),\n",
       " ('math.GM', 0.12087912087912088),\n",
       " ('math.HO', 0.4574780058651026)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(zip([index_to_cat[i] for i in range(32)],f1_score(y_true2, y_pred2, average=None)  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7166141608582824"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true2, y_pred2, average=\"weighted\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7181462931366613"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true2, y_pred2, average=\"micro\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7181462931366613"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true2,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1290   19   18   83   77   61   15   11   25   10    7    6   14    8\n",
      "    47   28    1    1    0    2    0   12    0    5    0    1   25    1\n",
      "     0    0    0    2]\n",
      " [  31 2532   37   77    1    4   62  150    8   20    7   34    8   31\n",
      "    18   19   34   12   11    2   10    1   10   18   28    0    6    5\n",
      "     1    0    4    7]\n",
      " [  26   41 1421    1    1   33    3  142    6    7    2   38    6   10\n",
      "    16    8    5    0   11   15   26    1   41    2    1    7    1   10\n",
      "    11    0    0    1]\n",
      " [ 118   67    0 1897   41    3   45   10   35   60   16    0   28    1\n",
      "     0   13    1  120    1    9    3    6    0    2    3    0    3    1\n",
      "     0    2    0    0]\n",
      " [ 220    7    4  110 2544   98    3    3   39   67   35    0  114    0\n",
      "     0   75    0    3    0   15    0    0    0    1    7    0   43    0\n",
      "     0    0    0    2]\n",
      " [  73    6   47    5   47 1151    3    3   18   12    6    6    6   34\n",
      "     8    7    5    1    1   23   12    2    0    1   21   20    8    3\n",
      "     0    1    0    0]\n",
      " [  36   43    0   18    1    1 2441   17    3   69    5    0   12    1\n",
      "     2    0    0   88    0    0    0    1    1    1    1    0    1    0\n",
      "     0    0    1    3]\n",
      " [  16   73   70    7    0    3    4 1568   10    0    3   25    0    2\n",
      "     2   31    9    0    8    2    0    0    3    4    2    0    2    0\n",
      "     0    0    3    2]\n",
      " [ 122   21   14   58   61   19   20   47  868   71   15    4   43    9\n",
      "     0   33   18    4    0   17    4   10    0    9    4    5    3    1\n",
      "     0    4    0    3]\n",
      " [  28   32    2   97   63   10  168    1   44 2130   21    0  137    0\n",
      "     0   10    1   70    0    2    3    0    1    7    5    0    3    0\n",
      "     0    1    0    2]\n",
      " [  50   11    5   44   64   14   10   18   16   18  747    8   11    0\n",
      "     0  104    6    9    9   27    2   37    1    9   18    1   38    0\n",
      "     1   14    1    2]\n",
      " [  25   28   41    1    0   13    0   35    1    0    7  517    0    0\n",
      "    59    3   29    0   30    1    4    5   10    0    0    1    0    9\n",
      "     9    0    1    0]\n",
      " [  90    6    4   37   63    5   35    5   12  109   17    0 1757    1\n",
      "     0   24    0   51    3    2    1    0    1    0    0    0    3    0\n",
      "     0    0    1    4]\n",
      " [   6    9   27    4    0   46    0    8   16    0    0    2    0  517\n",
      "    10    1   37    0    0    3   31    0    0    0    5    9    0    0\n",
      "     2    1    0    2]\n",
      " [  20    1    9    1    0    5    0    0    0    0    1   29    0   11\n",
      "   201    2    4    0   18    0   10   15    0    0    0    1    1    5\n",
      "     4    0    0    1]\n",
      " [  59   19   15   31   60   17    5   52   44   11  102    3   18    1\n",
      "     3  445    1    6    2   20    0    0    0    4   10    0   10    0\n",
      "     0    1    4    3]\n",
      " [   6   42   10    6    0   11    2   30    8    2    3   35    0   31\n",
      "     5    0  532    0   17    0   13    8    1    8    5    1    0    3\n",
      "     1    3    0    2]\n",
      " [   9    7    2  101    0    1   46    2    0   18    0    0   16    0\n",
      "     0    1    0  806    0    0    2    0    0    0    3    0    0    0\n",
      "     0    0    0    1]\n",
      " [  22   22   12    0    0    4    4   27    1    4   10   53    4    0\n",
      "    48    3   29    0  303    0    3    7   24    6    0    1    2   12\n",
      "     6    1    1    2]\n",
      " [  13    4   33    6   14   42    3   16   17    3   37    1    6    9\n",
      "     0   54    0    1    0  309    1    0    0    2    2    2    2    0\n",
      "     0    2    0    0]\n",
      " [  10   17   18    1    0   16    7    5    7    1    3    7    1   32\n",
      "    14    2    6    1    3    0  306    2    3    2    3    3    2   28\n",
      "    10    3    0    2]\n",
      " [  25    5    0   10    0    3    2    0    6    0   31    5    0    0\n",
      "    14    2    8    1   13    2    1  237    0    4    0    0    0    2\n",
      "     8    2    1    0]\n",
      " [   5   28   33    1    0    0    3   24    0    0    1    9    0    0\n",
      "     0    1    9    1   32    0    4    0  295    2    1    0    0    4\n",
      "     3    0    1    0]\n",
      " [   8   27   11    5    0    0    1   25    5    1    6    1    0    1\n",
      "     0    3   14    6   18    0    2   10    2  482    2    0    0   14\n",
      "     0   14    4   10]\n",
      " [   5   42    5   10   11   32    2    4   13    9   13    0    3    9\n",
      "     2   24    2    0    0    5    4    0    0    0  157    1    1    1\n",
      "     0    1    1    1]\n",
      " [   7    0   26    0    1   29    0    1    6    0    0    2    2   10\n",
      "     3    0    0    0    0    1    3    0    1    1    0  145    0    0\n",
      "     0    0    1    1]\n",
      " [  43   20    0    3   22    6    4    4    4    2   23    0    4    0\n",
      "     0    5    0    2    1    2    0    0    1    0    0    1  107    0\n",
      "     0    0    0    0]\n",
      " [   3    1    6    0    0    0    2    1    1    0    1    8    0    1\n",
      "     8    0    1    0    3    0   21    1    0    9    0    0    0  166\n",
      "     5    0    0    1]\n",
      " [   4    0   17    0    0    8    0    1    0    0    1    6    0    1\n",
      "     8    0    2    0    6    0   16    4    7    0    0    1    0    7\n",
      "    37    0    0    0]\n",
      " [   0    2    0    2    1    0    0    3    6    2   29    0    0    6\n",
      "     0    2    8    1    3    1    7    2    3   24    9    0    0    5\n",
      "     0   99    2    5]\n",
      " [   6   20    2    4    2    9    1   28    2    2    5    1    5    1\n",
      "     2    7    0    2    2    2    1    0    1    6    4    0    0    1\n",
      "     0    1   11   13]\n",
      " [  12   20    4   12    0    2    5   16    5    4    0    0    1    1\n",
      "     1    4    0    7    1    2    2    0    0    5    5    0    0    0\n",
      "     0    0    4   78]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "print(confusion_matrix(y_true2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc=0\n",
    "bad=[]\n",
    "for i in range(len(y_true2)):\n",
    "    if (y_true2[i]==y_pred2[i]):\n",
    "        \n",
    "        acc+=1\n",
    "    else:\n",
    "        bad+=[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.reset_index()\n",
    "bad_cat={}\n",
    "\n",
    "for index in bad:\n",
    "    cat=test.loc[index,\"categories\"][0]\n",
    "    if cat in bad_cat:\n",
    "        bad_cat[cat]+=[index]\n",
    "    else:\n",
    "        bad_cat[cat]=[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932\n",
      "consid reconstruct heterogen coeffici field robin boundari condit inaccess part boundari poisson problem uncertain unknown inhomogen conduct field interior domain account model error stem uncertainti conduct coeffici treat unknown conduct nuisanc paramet carri approxim premargin invert robin coeffici field approxim relat model error via bayesian approxim error bae approach uncertainti analysi present reli local linear paramet observ map maximum posteriori map estim lead normal gaussian approxim paramet posterior densiti comput map point appli inexact newton conjug gradient approach base adjoint methodolog construct covari made tractabl invok low rank approxim data misfit compon hessian two numer experi consid one prior covari conduct isotrop one prior covari conduct anisotrop result compar base standard error model particular emphasi feasibl posterior uncertainti estim show bae approach feasibl one sen predict posterior uncertainti consist actual estim error neglect relat model error yield infea estim robin coeffici addit demonstr bae approach approxim comput expen measur number pde solv convent error approach\n",
      "['math.OC', 'math.NA', 'math.ST']\n",
      "math.NA\n",
      "[('math.NA', 0.8670778), ('math.OC', 0.054623365), ('math.ST', 0.028264644), ('math.AP', 0.026105726)]\n",
      "[ 0  0  0  0  2  0  0  0  0  5  0  0 86  0  0  0  0  2  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "temp=bad[random.randint(0,len(bad))]\n",
    "print(temp)\n",
    "print(test.loc[temp,\"simple_abstract\"])\n",
    "print(test.loc[temp,\"categories\"])\n",
    "print(index_to_cat[y_pred[temp].argmax()])\n",
    "temp2=[]\n",
    "count=0\n",
    "for ind in y_pred[temp].argsort()[::-1]:\n",
    "    if count>3:\n",
    "        break\n",
    "    temp2+=[(index_to_cat[ind],y_pred[temp][ind])]\n",
    "    count+=1\n",
    "print(temp2)    \n",
    "print((y_pred[temp]*100).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
